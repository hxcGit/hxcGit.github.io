[{"categories":["daily"],"content":"文章描述","date":"2022-03-20","objectID":"/daily/","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["daily"],"content":"2022 年 3 月 24 日 周四 安排 raft 算法整理 华为比赛代码实现 bisect 资料检索 ","date":"2022-03-20","objectID":"/daily/:1:0","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["daily"],"content":"2022 年 3 月 23 日 周三 安排 区块链作业整理 commit bisect 优化资料检索 ","date":"2022-03-20","objectID":"/daily/:2:0","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["daily"],"content":"2022 年 3 月 16 日 周三 阅读材料 https://mp.weixin.qq.com/s/vTZXjq71MZPv9VGoOY6jPg https://segmentfault.com/a/1190000040263156 https://www.cnblogs.com/jo3yzhu/p/13559761.html 学习 https://jimmysong.io/kubernetes-handbook/concepts/crd.html 【暂缓】 CRD 定义【暂缓】 KubeBuilder 大概介绍【暂缓】 ","date":"2022-03-20","objectID":"/daily/:3:0","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["daily"],"content":"2022 年 3 月 15 日 周二 阅读材料 https://mp.weixin.qq.com/s/_7ofuy2Wp__3B9esO_2oag https://mp.weixin.qq.com/s/rbPMG4NF1g-xsfJeK0YY5A https://mp.weixin.qq.com/s/M0vJFnXaCawdmVsU8sJf7g 学习 Go: channel：https://golang.iswbm.com/c04/c04_04.html option 编程模式：https://mp.weixin.qq.com/s/_7ofuy2Wp__3B9esO_2oag Raven: 阅读相关源码，进一步梳理大纲 进度: 第二天 ","date":"2022-03-20","objectID":"/daily/:4:0","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["daily"],"content":"2022 年 3 月 14 日 周一 阅读材料 https://mp.weixin.qq.com/s/d6ur5HEUG3qeXAtFM6eE9A https://mp.weixin.qq.com/s/NjRI7gj8wBZExieWZFdYxw https://mp.weixin.qq.com/s/7uBRYNUAnfqjivKqpQFgRA https://mp.weixin.qq.com/s/yqPOlkjoDZLgfsO1XkaQvg https://mp.weixin.qq.com/s/P7B_H-0Qy7EEoaXTllULbQ 调研内容 华为技术挑战大赛 - 流量调度相关内容【初步了解了题目】 学习 阅读 submariner 相关源码 【已转向看 Raven，有了一丁丁点进展】 进度 ： 第一天 ","date":"2022-03-20","objectID":"/daily/:5:0","tags":["计划","plan","日程"],"title":"每日规划","uri":"/daily/"},{"categories":["architecture"],"content":"go插件化解决方案","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["architecture"],"content":"Go 插件化方案 ​ 关于 Golang 插件化方案，最近也调研了一些资料，这里做一个汇总，方便后续回顾与反思。其实之前没有深入思考过插件的问题，类似的应用场景有很多，当时只是觉得主应用暴露一个开放的接口，主应用与具体插件通过这个开放的接口进行交互而已，显然这种想法是错误的。  ","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/:1:0","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["architecture"],"content":"一、 Go 语言支持：动态链接库 plugin ​ Go Plugin 在 Go1.8 中正式引入，于 2016 年发布。Go plugin 机制主要实现了 Go 插件的加载与符号解析，可以将 Go 插件程序编译为共享库文件(.so)。主程序可以加载编译后的共享库文件，在程序中调用共享库的函数、变量等等，实现一个热插拔的插件系统。 Currently plugins are only supported on Linux, FreeBSD, and macOS. 1.1 使用 只需在编译时指定为插件模式即可 go build -buildmode=plugin API // 开启一个插件，如果已经被打开，返回现有的`*Plugin` func Open(path string)(*Plugin, error) // 搜索符号，返回interface，需要接口断言类型才能使用 func (p *Plugin) Lookup(symName string) (Symbol, error) 1.2 存在问题 目前不支持 windows，一开始只支持 Linux，后期增加 MacOS 版本限制严格，主程序与插件的 Go 版本需要一致，双方依赖的第三方版本库需要一致 不支持插件的关闭，同时插件只能新增无法更新，因此插件更新需要在文件名加上版本号，不然无法识别  ","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/:1:1","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["architecture"],"content":"二、 进程间通信 ​ 主要思想是核心程序与插件程序之间为不同的进程，双方通过生产者/消费者的模式进行通信，可以采用的通信方式有 RPC 或者消息队列等等。 主程序与插件间进程隔离 插件的管理一般可以通过监控特定的插件目录 一般该模式支持插件的上下线管理 常见解决方案 1. natefinch/pie https://github.com/natefinch/pie 基于 go RPC 2. hashicorp/go-plugin https://github.com/hashicorp/go-plugin 基于 go RPC 或 gRPC 3. go-mangos/mangos https://github.com/nanomsg/mangos 基于消息队列  ","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/:1:2","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["architecture"],"content":"三、 嵌入脚本语言 ​ go 是编译型语言，在程序运行之前就将程序编译成 OS 可以直接识别的机器码文件。而这就限制了 go 语言本身不具备动态调整代码功能的能力，通过“内嵌脚本语言”则可能完成一些功能方面的扩展。对内嵌脚本语言进行了基本的了解，主要的结构一般是在主应用内嵌脚本语言解释器，然后调用脚本执行，一般可调用的语言都是解释性语言。具体的内容尚未通过实验验证，后续可以尝试。 常见嵌入式脚本语言 1. anko https://github.com/mattn/anko Go 语言编写的可编写脚本的解释器 2. otto https://github.com/robertkrimen/otto 用 Go 编写的 JavaScript 解释器 3. gop https://github.com/goplus/gop 七牛开源，曾叫 Q 语言 4. gopher-lua https://github.com/yuin/gopher-lua Lua in go 5. tengo https://github.com/d5/tengo Go 语言编写的解释器  ","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/:1:3","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["architecture"],"content":"四、 总结 ​ 总的来时，以上就是我调研到到相关内容。由于只是一个大方向的设计方案，没有实际的操作，很多优缺点也只是参照网络评论以及博客的一面之词。当然，很多问题也是显而易见的，比如 Go 官方 plugin 要求开发版本强一致的问题，这一问题一定是一个非常恶心的限制。 ​ 从调研结果来看，在理想情况下采用原生的 plugin 机制必然是优解，其效率应该是高于另外二者的，并且这样的项目看起来似乎也会更加自然。但是由于各种各样的问题，原生 plugin 机制并不是非常的完美，从相关的 issue 讨论来看，Go 官方对其似乎也不是非常上心。 ​ 权衡之下，可能采用进程间通信调用的方式可能会是一个比较优秀的选择。不但可以提供一个完整的插件功能机制，包括插件上下线管理、插件发现、插件更新以及多语言支持等等，而且在微服务流行的趋势下，采用 RPC 等方式也是一个可以接受的选择。相比而言，嵌入解释性语言，可能会显得更加难以理解和操作（至少对我来说如此），同时相关的应用案例与解决方案模板似乎并不多见。  https://pkg.go.dev/plugin https://eddycjy.com/posts/go/plugin/ https://cloud.tencent.com/developer/article/1187560 https://www.topgoer.com/%E5%BC%80%E6%BA%90/%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80.html https://github.com/robertkrimen/otto https://segmentfault.com/a/1190000040875946 https://www.zhihu.com/question/266551236 ","date":"2022-05-19","objectID":"/plugin%E6%9C%BA%E5%88%B6/:1:4","tags":["plugin","scheme"],"title":"Plugin机制","uri":"/plugin%E6%9C%BA%E5%88%B6/"},{"categories":["native cloud"],"content":"gRPC调研","date":"2022-05-17","objectID":"/grpc/","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"初探  最近接触到了开源之夏这个活动，其中有个项目是构建一个基于 gRPC 的轻量化插件方案。之前学习 RPC 时曾经了解过 gRPC 的相关内容，并尝试了简单的 demo 程序，但是没有深入窥探其内在机理与核心。借此次机会，对 gRPC 这个当下异常火爆的远程过程调用系统进行再探，希望能够究其根本。以下记录了该次的调研内容。 *No silver Bullet* ​ 查询资料时，发现了一个非常有意思的词——“银弹”。之前好像确实听过这么一个说法，又忽然见到，像是重逢却想不起来她的名字。只好尴尬地再问一次：您是？其实“Silver Bullet“是 Fred Brooks 在 1987 年发表的”Essence and Accidents of Software Engineering“论文提及了该说法。深究来说，该说法应该源于美国的狼人故事，即狼人会在月圆之夜变身，而 silver bullet 则是可以迅速 kill 狼人的武器。这里，银弹就被引申成“解决复杂问题良方”的意思，那么作者其实是认为\"There is no silver bullet !\" 具体作者为啥如此说，之后可能需要具体看看论文以及其《人月神话》了～ ","date":"2022-05-17","objectID":"/grpc/:1:0","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"起源 ​ gRPC 起源于谷歌(真有那么强吗？k8s 也是)，在此之前谷歌使用的是另一个叫做 stubby 的通用 RPC 框架，用来连接内部跨越数据中心的众多异构微服务，stubby 核心 RPC 层每秒能处理数百亿次的请求，但是 stubby 与谷歌内部耦合太强，所以谷歌开源了 gRPC——一个类似于 stubby 的 RPC 框架。（为何要开源内部的项目？这可能是一个非常值得探究的问题，对于商业企业开源究竟有何好处？可能还需要我多多接触开源、多多旁听才有收获） ​ 总之，2015 年 gRPC 开源，这个 gRPC 框架相比 stubby 更加通用，同时兼顾跨平台、可扩展以及性能高效等等特点。此后，gRPC 大受欢迎，并且加入了 CNCF，也由此获得了巨大发展动力。（其实 gRPC 框架非常火热背后没准靠的也有谷歌背书的成分，最近也有看到知乎贾扬清的回答：国内开源项目大多靠开源项目的母公司来推动、运营；国外开源项目大多靠社区本身、项目贡献者等等来推动发展。这里看来也不完全这样，大多数可能更是二者的结合）。  ","date":"2022-05-17","objectID":"/grpc/:1:1","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"一、 基本概念 ​ 了解了 gRPC 的起源之后，就该学习 gRPC 的具体内容啦。首先，gRPC 实质是进程间通信技术，可以在分布式异构应用间进行远程服务调用，就像调用本地函数一样。在开发 gRPC 应用时，需要先定义服务接口，其中应该包含消费者消费服务的方式、消费者可以远程调用的方法以及调用这些方法需要使用的参数和消息格式，定义服务所使用的语言称为接口定义语言（Interface definition language，IDL）。 1.1 服务定义 ​ gRPC 使用protocol buffers作为 IDL 来定义接口服务。Protocol buffers是一种语言中立、平台无关以及数据结构化的数据序列化机制（序列化其实就是将内存中的变量变为可存储或可传输的过程）。其实这里还对应了marshal与unmarshal两个动作，marshal是将 RPC 的请求转换成对应的 pb 格式；unmarshal将相应的二进制 pb 又转换成过程调用。 ​ 服务接口一般定义在proto文件中，同时我们可以通过 gRPC 相关的插件来根据proto文件生成代码，go 一般可以使用工具protoc-gen-go。此外在服务定义时，用户定义的类型中每个字段都需要具有唯一的编号名（比如 string id = 1），这样做的目的是在二进制形式的消息中，可以通过编号来识别相应的字段。 // 结构一般如下 syntax = \"proto3\"; // 一般采用version 3 package ... // 可以通过包名来防止协议消息类型之间发生命名冲突 service foo { rpc add(Bar) returns (BarID); rpc get(BarID) returns (Bar);}message Bar { string id = 1; string name = 2;}message BarID { string value = 1;}  1.2 基本流程 服务端 实现 gRPC 服务接口，生成服务端 skeleton 的逻辑。 注册服务到 gRPC 服务器。 运行 gRPC 服务器，监听来自客户端的请求并返回响应。 客户端 建立与远程服务器的连接 将客户端 stub 与 gRPC 连接关联 通过客户端 stub 调用远程方法  ","date":"2022-05-17","objectID":"/grpc/:1:2","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"二、 对比方案 ​ gRPC 虽说感觉非常高大上，其实也只是众多进程间通信方式的一种，如果想更好的理解 What gRPC、Why gRPH、How gRPC，最好的办法就是看看类似的解决方案。刚好网上关于对比解决方案的介绍也很多，就大概浏览一下。 2.1 REST ​ 描述性状态迁移（Representational state transfer，REST最早由 Roy Fielding 的博士论文提出，是一种面向资源的思想。使用 REST 的系统中，将应用程序建模成资源的集合，客户端可以查询、变更这些资源的状态。 ​ 在常见的业界解决方案中，RESTful/HTTP + JSON 是一种标准的服务提供方式。资源的操作可以通过 HTTP 相关操作（GET、POST、PUT、DELETE、PATCH）提供，媒体类型（MIME）可以有 JSON、XML、YAML 等等。 ​ 虽然 RESTful+JSON 风格的服务方式已经非常成熟且常见，但是确实也存在一些问题，而这也是 gRPC 或者 RPC 框架逐渐被应用的原因之一。以下调研了一些常见的缺陷： (1) 消息传递低效 ​ RESTful 风格的服务是基于 HTTP 的文本传输协议，这些传输信息虽然采用的是可读的文本格式，但是对于信息的传输而言，可读性却是一项无用的功能。采用文本化的格式，是导致消息传递低效的重要原因。 (2) 缺乏强类型接口 ​ 微服务之间可以通过 RESTful 风格的接口进行交互，但是 RESTful 服务却没有定义强类型的服务接口。通俗来说，服务的提供者与服务的消费者需要“对接口”，这一点我的感受是非常强烈的，最近也在进行一个前后端交互的 Web 项目，其中就涉及到大量的前后端接口对接。我们采用的方案是使用一些接口定义方案(OpenAPI/Swagger)以及接口管理工具(Apifox、yapi)等等，总的使用感觉就是需要花费学习时间、撰写文档时间以及沟通交流时间。《grpc 与云原生应用开发》中说的非常好，“RESTful 并没有与底层的架构风格或消息协议紧密集成在一起”。其实 Swagger 以及相关接口管理工具都是一种事后补救的措施，来规则接口的类型定义。  2.2 Thrift ​ Apache Thrift 是类似 gRPC 的 RPC 框架，由 Facebook 开发，后期捐赠与 Apache。Thrift 有相应的接口定义语言同时提供了多编程语言的支持。可以在文件中定义数据类型和服务接口，同样支持生成客户端与服务端代码（可以发现 Thrift 与 gRPC 其实在某些方面非常相似，是否意味着现代的 RPC 框架都需要具有这些功能或者特点）。 ​ Thrift 独特的地方在于其传输层为网络 I/O 提供了抽象，可以将 Thrift 从系统中其他组件中解藕，可以在任意的传输实现上运行，如 TCP、HTTP 等。  2.3 GraphQL ​ 这是我第二次听说 GraphQL 这个项目，第一次是听说，第二次是发现该项技术可以用在进程间通信。而且！似乎这项技术的应用逐渐扩大化，看来见识还是短浅了。该项目同样是 Facebook 发起并开源标准化的项目，这是一门针对 API 的查询语言。 ​ GraphQL 提供了一种允许客户端定义希望获得的数据、获取数据的方式以及数据格式的方法。由于时间的限制，仅仅是对该项目官网进行简单的了解，后期可以进行相关实验，深入查看一番。 ​ 根据相关介绍，GraphQL 更适合面向外部的服务或者 API，这是其比较特殊的特性。  2.4 gRPC 优势 ​ 其实也有一些常见的其他 RPC 框架，也有大概浏览一下，但是没有深入了解，就暂时只对比了 REST 与 gRPC 这两个功能相似却又不太一样的方案。从中其实可以发现 gRPC 存在的一些非常显著的优势。 (1) 通信效率高 ​ 效率高是 gRPC 框架的一个显著优点，采用protocol buffers的二进制方案，并且基于 HTTP/2 通信。 (2) 服务接口简单 ​ gRPC 通过proto文件预先定义服务接口以及消息类型，之后才能进行具体逻辑的开发，通过这种方式 gRPC 提供了简单且强类型的接口模式。 (3) 支持多语言 ​ 这可能不算是一个特别的优势，比如大多数的 RPC 框架以及 RESTful 架构等都支持多语言。可能早期的 java-dubbo 等只支持 java 语言。 (4) 支持双工流 ​ 基于 HTTP/2 的传输协议，gRPC 在服务端与客户端原生支持流，可以方便的开发流服务或流客户端。  2.5 gRPC 劣势 (1) 不适合面向外部的服务 ​ gRPC 由于强类型的接口服务约束，限制了暴露服务的灵活性。一般来说，gRPC 更适合系统内部的服务交互，而对外暴露服务可能更适合通过 REST 或者 GraphQL 的方式进行。严格的来说，这并不算是 gRPC 的问题，只是应用场景的限制罢了，最多可以说是全面性不够。 (2) 服务定义变更复杂 ​ 由于 gRPC 服务定义的变更，可能需要重新生成服务端以及客户端的代码，进而影响到业务逻辑甚至是整个开发环境，因此服务定义变更是一件比较棘手或者复杂的事情。但是，通过前期严格规范、后期禁止破坏性变更以及通过版本升级规避变更的方式可以在一定程度上减轻服务定义变更带来的问题。  ","date":"2022-05-17","objectID":"/grpc/:1:3","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"三、 通信模式 (1) 一元 RPC 模式 ​ 该模式下，客户端调用服务端的远程方法时，客户端发送请求至服务端并获取一个响应。基础内容中介绍的就是一元 RPC 模式，不再重复。 (2) 服务端、客户端单向流模式 ​ 该类模式下，服务端流则可以在接受到客户端的请求后，发送多个响应；客户端流可以发送多个请求。单向流模式下，需要在 rpc 服务定义中增加关键字stream service foo1 { rpc add(...) returns (stream ...)}// 或 service foo2 { rpc add(stream ...) returns (...)} 单向流模式中，可以通过stream.Send()方法发送流消息，通过stream.Recv()方法来接受流消息，通过return nil来标记流结束并在接受端通过err == io.EOF判断流的结束 对于服务端流模式，一定是在服务端收到客户端请求后才可以发送流；而对于客户端流模式，服务端不一定要等到从客户端接受所有的流消息后才发送响应，在收到任意数量流消息后均可以通过stream.SendAndClose()方法响应。 (3) 双向流 RPC 模式 ​ 在双向流 RPC 模式中，客户端以消息流的形式发送请求到服务端，服务端也以消息流的形式进行响应，但是调用必须由客户端发起。因此，双向流 RPC 是一种比较复杂但是很灵活的通信方式，客户端发起请求后，双方可以通过任意的交互顺序通信，这主要取决于逻辑代码的定义，并且双方也都可以在任意时间关闭流并告知对方。  ","date":"2022-05-17","objectID":"/grpc/:1:4","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"四、底层原理 ","date":"2022-05-17","objectID":"/grpc/:1:5","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"五、 相关配置 拦截器 截止时间、取消 多路复用 安全性 负载均衡 ","date":"2022-05-17","objectID":"/grpc/:1:6","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["native cloud"],"content":"六、 其他 https://zh.wikipedia.org/wiki/%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D https://doc.oschina.net/grpc?t=58008 https://developers.google.com/protocol-buffers https://www.ruanyifeng.com/blog/2011/09/restful.html https://cloud.tencent.com/developer/article/1845449 https://grpc.io/docs/languages/go/quickstart/ https://juejin.cn/post/6984961473378271245 https://thrift.apache.org/ https://graphql.cn/learn/ ","date":"2022-05-17","objectID":"/grpc/:1:7","tags":["RPC","HTTP2"],"title":"GRPC","uri":"/grpc/"},{"categories":["go"],"content":"go 读写锁RWMutex的优先级与相关问题 https://zhuanlan.zhihu.com/p/349590549 https://www.techclone.cn/post/tech/go/go-rwlock/#%E5%8F%82%E8%80%83 ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:0","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["go"],"content":"一、 前情提要 https://golang.iswbm.com/c04/c04_06.html 学习RWMutex锁时，看例子代码，发现对优先级产生困惑 package main import ( \"fmt\" \"sync\" \"time\" ) func main() { lock := \u0026sync.RWMutex{} lock.Lock() for i := 0; i \u003c 4; i++ { go func(i int) { fmt.Printf(\"第 %d 个协程准备开始... \\n\", i) lock.RLock() fmt.Printf(\"第 %d 个协程获得读锁, sleep 1s 后，释放锁\\n\", i) time.Sleep(time.Second) lock.RUnlock() }(i) } time.Sleep(time.Second * 2) fmt.Println(\"准备释放写锁，读锁不再阻塞\") // 写锁一释放，读锁就自由了 lock.Unlock() // 由于会等到读锁全部释放，才能获得写锁 // 因为这里一定会在上面 4 个协程全部完成才能往下走 lock.Lock() fmt.Println(\"程序退出...\") lock.Unlock() } 主要困惑在于第 16 行的Rlock()读锁和第 31 行的Lock()写锁的优先级不同呢？ Lock()总是在Lock()之前获得锁 1. 原因分析 请教了技术交流群，“golang 梦工厂群”中有群友给出了读写锁优先级问题的博客 https://www.techclone.cn/post/tech/go/go-rwlock/#%E5%8F%82%E8%80%83 自我分析 go 设计中读锁时优于写锁的 go 设计中读锁写锁公用一个等待队列，16 行的读锁先入队，所以优先获得锁 2. 代码修改测试 改动了核心代码发现存在问题 说明并不一定是一个统一的等待队列，不然 4 协程应该在“程序退出”协程之前获得锁 此处还存在问题，为啥“程序退出”之后，4 协程还会运行？ 说明真的不是存在统一的等待队列，但是为啥这里是会直接运行“程序退出”之后就退出了呢？而不运行其他协程了 ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:1","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["go"],"content":"二、 读写锁优先级问题 2.1 读优先 读者来 无读者，无写者 ：新读者可读 有读者读，无写者 ： 新读者可读 有读者读，有写者等 ： 新读者可读 无读者，有写者写 ： 新读者等 写者来 无读者，无写者 ： 新写者写 有读者，无写者 ： 新写者等 无读者，有写者 ： 新写者等 核心思想是有读者读，新读者就可以一直读，写者就要一直等待 2.2 写优先 读者来 无读者，无写者 ： 新读者读 有读者读，无写者 ： 新读者读 有读者读，有写者等 ： 新读者等 无读者，有写者写 ： 新读者等 写者来 无读者，无写者 ： 新写者写 有读者，无写者 ： 新写者等 有写者或有写者等 ： 新写者等 核心思想就是在有读者读且有写者等时，如果有新的读者来，这时是不让读的，需要等待 ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:2","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["go"],"content":"三、 RWMutex 源码分析 3.1 字段定义 type RWMutex struct { w Mutex // 写锁的互斥量 writerSem uint32 // writer信号量，没有读锁后释放该信号量 readerSem uint32 // reader信号量，没有写锁后释放该信号量 readerCount int32 // 当前读锁的数量，包括已经加锁的读锁数量以及等待加锁的读锁数量 readerWait int32 // 写锁阻塞时，active的读锁数量 } const rwmutexMaxReaders = 1 \u003c\u003c 30 // 最大的读锁数量上限 3.2 Rlock() func (rw *RWMutex) RLock() { if atomic.AddInt32(\u0026rw.readerCount, 1) \u003c 0 { runtime_SemacquireMutex(\u0026rw.readerSem, false, 0) } } 读锁请求加锁时，关键是判断readerCount加一后是否还小于 0，如果还小于 0，说明存在写锁，则读锁请求阻塞 3.3 RUlock() func (rw *RWMutex) RUnlock() { if r := atomic.AddInt32(\u0026rw.readerCount, -1); r \u003c 0 { rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { if atomic.AddInt32(\u0026rw.readerWait, -1) == 0 { // 最后一个reader了，writer终于有机会获得锁了 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } 解锁就是将 readerCount-1，如果减完发现小于 0，说明有写锁请求在等待，就需要调用rUnlockSlow()来释放readerWait rUnlockSlow主要功能是将readerWait-1,如果发现readerWait==0 说明已经没有 active 的读锁，则可以释放writerSem信号量，唤醒阻塞的写锁请求进程 3.4 Lock() func (rw *RWMutex) Lock() { rw.w.Lock() r := atomic.AddInt32(\u0026rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders if r != 0 \u0026\u0026 atomic.AddInt32(\u0026rw.readerWait, r) != 0 { runtime_SemacquireMutex(\u0026rw.writerSem, false, 0) } } 写锁时，先通过rw.w.Lock()解决与其他写锁的互斥问题 其中细节还需要再研究 将readerCount-rwmutexMaxReaders即设置成负数，以此来通知读锁请求，有写锁来了 令r等于原readerCount的值，如果不为 0 且没有存active读锁，则写锁请求阻塞 atomic.AddInt32(\u0026rw.readerWait, r) != 0时将当前active读锁赋值给readerWait,也只有此处会赋值，readerWait--只会在读锁释放时才有 3.5 Unlock() func (rw *RWMutex) Unlock() { // 告诉reader没有活跃的writer了 r := atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders) // 唤醒阻塞的reader们 for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放内部的互斥锁 rw.w.Unlock() } 释放写锁时，将readerCount恢复成读锁数量原值 循环唤醒阻塞的写进程 所以，在写锁释放的过程中，读锁请求获得锁的优先级是大于写锁的 rw.w.Unlock()最后释放写锁间互斥的信号量w ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:3","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["go"],"content":"四、 总结 没有读写进程的前提下，读写锁是同等地位竞争的 写锁释放过程中，读锁的优先级是高于写锁的 读锁占用时，写锁请求到达后，后续的读锁请求都会被阻塞 ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:4","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["go"],"content":"五、 避坑 不可复制 复制的 RWMutex 实例里面会带有各种计数器，信号量，直接复制的话这些状态会被保留 不可重入 与普通Mutex相同，即不能锁两次 场景一 一个进程Lock()后又Lock(),本质上是前一个Lock()由于后一个Lock()阻塞无法往下推进，也就无法释放锁，而第二个Lock()由于锁被前一个Lock()占用导致阻塞 场景二 与场景一类似，先RLock(),再Lock() 场景三 一道面试题的场景，读进程 A 会递归调用读进程 A1，写进程 B，先执行 A 加读锁，这时如果并发执行到 B，则由于写锁请求到达，则 A1 无法加读锁，需要等待，就变成 A 等待 A1（A1 被 B 阻塞），B 等待 A 释放 ","date":"2022-04-02","objectID":"/go%E8%AF%BB%E5%86%99%E9%94%81/:1:5","tags":["go","同步","锁","读写锁"],"title":"Go读写锁","uri":"/go%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["git"],"content":"git信息比较","date":"2022-04-01","objectID":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/","tags":["git"],"title":"git信息比较","uri":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/"},{"categories":["git"],"content":"git 信息比较 ","date":"2022-04-01","objectID":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/:1:0","tags":["git"],"title":"git信息比较","uri":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/"},{"categories":["git"],"content":"一、 diff 比较 git 文件变动存在三种比较 见 git 三种存储区域 工作区和暂存区比较 git diff 暂存区与仓库比较 git diff --cached 工作区与仓库比较 git diff HEAD # HEAD此处相当于是commit记录，可以换成其他commit记录 ","date":"2022-04-01","objectID":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/:1:1","tags":["git"],"title":"git信息比较","uri":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/"},{"categories":["git"],"content":"二、 status 显示信息 普通git status 显示没有 track 的文件 显示暂存区与仓库差异 显示工作区与暂存区差异 git status -s或git status --short 输出紧凑信息 $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt ??表示未跟踪的信息 ","date":"2022-04-01","objectID":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/:1:2","tags":["git"],"title":"git信息比较","uri":"/git%E4%BF%A1%E6%81%AF%E6%AF%94%E8%BE%83/"},{"categories":["git"],"content":"git首页","date":"2022-04-01","objectID":"/git/","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":"1、git 信息比较 2、git 忽略文件 3、git 撤销 4、git 标签","date":"2022-04-01","objectID":"/git/:0:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":"git ignore相关内容","date":"2022-04-01","objectID":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/","tags":["git"],"title":"git忽略文件","uri":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/"},{"categories":["git"],"content":"忽略文件 .gitignore *.[oa] *~ ","date":"2022-04-01","objectID":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/:1:0","tags":["git"],"title":"git忽略文件","uri":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/"},{"categories":["git"],"content":"一、 规范 所有空行或者以 # 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配 匹配模式可以以(/)开头防止递归 匹配模式可以以(/)结尾指定目录 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号(!)取反 ","date":"2022-04-01","objectID":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/:1:1","tags":["git"],"title":"git忽略文件","uri":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/"},{"categories":["git"],"content":"二、 glob 模式匹配（shell 中简化的正则表达式） 星号(*)匹配零个或多个任意字符 [abc] 匹配任何一个列在方括号中的字符(这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c) 问号(?)只匹配一个任意字符 如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配(比如 [0-9] 表示匹配所有 0 到 9 的数字) 使用两个星号(*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等 附录 github 上针对项目和语言的.gitignore 文件列表 https://github.com/github/gitignore ","date":"2022-04-01","objectID":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/:1:2","tags":["git"],"title":"git忽略文件","uri":"/git%E5%BF%BD%E7%95%A5%E6%96%87%E4%BB%B6/"},{"categories":["git"],"content":"git撤销","date":"2022-04-01","objectID":"/git%E6%92%A4%E9%94%80/","tags":["git"],"title":"git撤销","uri":"/git%E6%92%A4%E9%94%80/"},{"categories":["git"],"content":"git 撤销操作 ","date":"2022-04-01","objectID":"/git%E6%92%A4%E9%94%80/:1:0","tags":["git"],"title":"git撤销","uri":"/git%E6%92%A4%E9%94%80/"},{"categories":["git"],"content":"一、 丢弃工作修改 # 注意 \"--\"\" 一定不要忘记，不然就变成切换分支 # 当修改了文件，没有add时，checkout是丢弃工作区修改 # 当修改了文件，add后，又修改了文件，checkout是丢弃工作区修改，回到上一次add时的状态 git checkout -- file-name ","date":"2022-04-01","objectID":"/git%E6%92%A4%E9%94%80/:1:1","tags":["git"],"title":"git撤销","uri":"/git%E6%92%A4%E9%94%80/"},{"categories":["git"],"content":"二、 撤销add git restore --staged file-name git reset file-name git reset不加参数时时安全的 上述两个命令功能一致 ","date":"2022-04-01","objectID":"/git%E6%92%A4%E9%94%80/:1:2","tags":["git"],"title":"git撤销","uri":"/git%E6%92%A4%E9%94%80/"},{"categories":["git"],"content":"三、 撤销commit 3.1 修改最后一次提交 git commit --amend # 上次commit内容后，发现有改动需要一起提交，那么可以通过--amend重新发起这次commit 3.2 回退 commit # 回退到当前版本的上一个版本 git reset --hard HEAD^ git 内部有个指向当前版本的 HEAD 指针，版本回退或者前进时，git 仅仅是将 HEAD 指向位置改变 上述HEAD^也可以改成某次提交的 commit ID ","date":"2022-04-01","objectID":"/git%E6%92%A4%E9%94%80/:1:3","tags":["git"],"title":"git撤销","uri":"/git%E6%92%A4%E9%94%80/"},{"categories":["git"],"content":"git标签相关内容","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"git 标签 ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:0","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"一、 列出标签 git tag # 以字母顺序列出标签 git tag -l 'v1.8.5*' # 列出所有1.8.5系列的标签 ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:1","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"二、 创建标签 两种类型的标签：轻量标签（lightweight）和附注标签（annotated） lightweight 标签只是一个提交的引用，不包含一些信息，annotated 标签含有信息包括“打标签者名字”，“电子邮件地址”，“日期与时间”，“GPG 签名与验证”等； ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:2","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"三、 annotated 标签 git tag -a v1.4 -m \"my version 1.4\" # 使用-a选项可以创建annotated标签 # 使用-m选项输入说明信息，如果没有指定，则git会运行编辑器要求输入信息 $ git show v1.4 tag v1.4 Tagger: Ben Straub \u003cben@straub.cc\u003e Date: Sat May 3 20:19:12 2014 -0700 my version 1.4 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u003cschacon@gee-mail.com\u003e Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:3","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"四、 lightweight 标签 lw 标签实际上只是将提交校验和存储到一个文件中，没有保存其他信息 创建时不要使用-a选项，直接提供标签名称即可创建 lw 标签 # 这里用的应该就是lw标签 git show v0.6.0 #openyurt # 使用git show可以查看某个tag的相关信息 commit 7df5fd6a019e28ee4147a4b271f7ada91e6372a9 (tag: v0.6.0, origin/release-v0.6) Author: rambohe \u003clinbo.hlb@alibaba-inc.com\u003e Date: Wed Jan 12 10:39:06 2022 +0800 [docs] revise readme and changelog for OpenYurt v0.6.0 (#709) ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:4","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"五、 推送标签 默认情况下，git push命令不会推送 tag 至服务器 方式一 git push origin [tagname]类似推送分支的方式 git push --tags 会将所有不在远程仓库的标签全部推送 ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:5","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["git"],"content":"六、 检出标签 git 中标签不能像分支一样来回移动 git checkout -b [branchname] [tagname]可以在特定的标签上创建新分支 实质上相当于是使用 tag 标签这个版本创建一个新的分支 【注意】如果该 branchname 分支有了新的改动的话，那么其实代码和对应的 tagname 就不一样了 ","date":"2022-04-01","objectID":"/git%E6%A0%87%E7%AD%BE/:1:6","tags":["git"],"title":"git标签","uri":"/git%E6%A0%87%E7%AD%BE/"},{"categories":["专业基础"],"content":"Paxos分布式算法学习","date":"2022-03-22","objectID":"/paxos/","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"Paxos 资料链接 https://zhuanlan.zhihu.com/p/31780743 https://www.cnblogs.com/linbingdong/p/6253479.html https://blog.openacid.com/algo/paxos/ chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=https%3A%2F%2Fongardie.net%2Fstatic%2Fraft%2Fuserstudy%2Fpaxos.pdf ","date":"2022-03-22","objectID":"/paxos/:1:0","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"一、 背景问题 维基百科 Paxos 是莱斯利·兰伯特（Leslie Lamport），1990 年提出的一种基于消息传递且具有高度容错特性的共识算法 Paxos 常被误称为一致性（consistency）算法，但是 consistency 和 consensus 并不是一个概念。Paxos 是一个共识算法 问题背景 在分布式系统中，会发生各种异常错误情况，如何在一个分布式系统中，快速正确地对某个数据达成共识？Paxos 算法运行在系统中出现宕机故障，可以容忍消息的丢失、延迟、乱序以及重复，但是不考虑 Assume a collection of processes that can propose values. A consensus algorithm ensures that a single one among the proposed values is chosen. If no value is proposed, then no value should be chosen. ","date":"2022-03-22","objectID":"/paxos/:1:1","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"二、 角色 Proposer ： 提出提案（Proposal）。Proposal 信息包括提案编号（Proposal ID）和提议的值（Value） Acceptor ：参与决策，回应 Proposers 的提案。收到提案后可以接受提案，若提案获得大多数接受，则称该提案被批准 Learner ： 不参与决策，从 Proposers/Acceptors 学习达成一致的提案 ","date":"2022-03-22","objectID":"/paxos/:1:2","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"三、 算法流程 Phase 1. ​ (a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors ​ (b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, then it responds to the request with a promise not to accept any more proposals numbered less than n and with the highest-numbered proposal (if any) that it has accepted. Prepare阶段生成的 number ID 可使用时间戳 ➕Server ID Acceptor进行Promise的承诺 （1）两个 Promise Acceptor 不接受 Proposal ID 小于等于当前请求的Prepare请求 Acceptor 不接受 Proposal ID 小于当前请求的Propose请求 注意上面区别 （2）一个 Accept 回复已经接受过的提案中 Proposal ID 最大的那个提案的 Value（这个 Value 会被 Proposer 接收到后并学习） Phase 2. ​ (a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v, where v is the value of the highest-numbered proposal among the reponses, or is any value if the responses reported no proposals. ​ (b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n. ","date":"2022-03-22","objectID":"/paxos/:1:3","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"四、 Safety Only a value that has been proposed may be chosen Only a single value is chosen, and a process never learns that a value has been chosen unless it actually has been Requirement P1. An acceptor must accept the first proposal that it receives. （acceptor 必须接受它收到的第一个 proposal） But this requirement raises a problem. Several values could be proposed by different proposers at about the same time, leading to a situation in which every acceptor has accepted a value, but no single value is accepted by a majority of them. Even with just two proposed values, if each is accepted by about half the acceptors, failure of a single acceptor could make it impossibleto learn which of the values was chosen. P1a. An acceptor can accept a proposal numbered n iff it has not responded to a prepare request having a number greater than n P2. If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v.（如果值为 v 的 proposal 被选定，则任何被选定的具有更高编号的 proposal 值也一定是 v） Chosen ： A value is chosen when a single proposal with that value has been accepted by a majority of the acceptors. Since numbers are totally ordered, condition P2 guarantees the crucial safetyproperty that only a single value is chosen. (保证只有一个值被选中) P2a. If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v. （如果值为 v 的 proposal 被选定，则对所有的 acceptor，他们接受的任何具有更高编号的 proposal 的值也一定是 v） P2b. If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposer has value v. （如果值为 v 的 proposal 被选定，则对所有的 proposer，他们提出的任何具有更高编号的 proposal 值也一定为 v） P2c. For any v and n, if a proposal with value v and number n is issued, then there is a set S consisting of a majority of acceptors such that either (a) no acceptor in S has accepted any proposal numbered less than n, or (b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S ","date":"2022-03-22","objectID":"/paxos/:1:4","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"五、 活锁 Liveness 多个 proposer 同时运行时，各个 proposal 的编号交替增加，没有任何的 proposal 可以被成功接受 解决 随机延迟，停等（有点类似于 CSMA 解决冲突的思路） 通过选主，只有主 Proposer 才能提出提案 ","date":"2022-03-22","objectID":"/paxos/:1:5","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"拓展资料 ","date":"2022-03-22","objectID":"/paxos/:2:0","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"B 站视频 1. CAP Theorem 一致性 consistency 可用性 availability 分区容错性 partition tolerance 2. 一致性模型 弱一致性 最终一致性 ： 立马读取可能结果不对 DNS（Domain Name System） Gossip（Cassandra 的通信协议） 强一致性 Paxos Raft（multi-paxos） ZAB（multi-paxos） 分布式系统对 fault tolorence 的一般解决方案是 state machine replication 讨论的主题也就是 state machine replication 的共识（consensus）算法 ","date":"2022-03-22","objectID":"/paxos/:2:1","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"OpenACID Blog 学习 1. 核心思想 在廉价的易损设备上，通过多副本的冗余策略实现可靠性 注意此处与 Paxos 的区别，此处在数据库感觉更多的是为了让修改记录落盘，实现一致性，而不是在多个值中选一个进行共识 给出了一个数据。 多副本的数据丢失风险 1 副本 ～ 0.63% 2 副本 ～ 0.00395% 3 副本 ～ 0.000001% n 副本 ～ x^n （x=单副本损坏率） 2. 常见方案 一、 主从异步复制（Mysql 的 binlog 复制） 思路：应该只有主能够写，主收到写请求后，写入本地磁盘，然后返回响应，再同步给其他从节点 问题：在返回响应与同步至从节点之间存在异步，如果此时断电或者主损坏，则数据丢失 二、主从同步复制 思路：应该只有主能够写，主收到写请求后，写入本地磁盘，然后同步给其他从节点，再返回响应 问题：主返回响应之前需要确保同步到所有的从节点，这样效率很低，速度很慢，同时如果有从节点出现问题，则整个完成就完全阻塞 三、 主从半同步复制 思路：应该只有主能够写，主收到写请求后，写入本地磁盘，然后同步给一些从节点（不是全部），再返回响应 问题：如果数据 a 复制给从 1 节点，数据 b 复制给从 2 节点，结果 master 宕机，则从 slave1 和 slave2 恢复出的数据是不一样的，就是说半同步复制还是会存在数据不一致问题 四、多数派写（读） 思路：每条数据必须写入到半数以上机器上，每次读取数据都必须检查半数以上机器是否存在该条数据 问题 1：node1 和 node2 都写入了 a=x，下一次更新时 node2 和 node3 写入了 a=y，这时如果客户读取 node1 和 node2 会发现不一致， 解决 1：通过比较记录时间戳，来选择最新的状态，保证不产生歧义 问题 2：如果客户在写入 a=y 时，只写了 node3 的，node2 还没写进去就挂了，此时个节点中最新的状态 node1-x；node2-x；node3-y，则如果客户读取 node1 和 node2 会得到 x；读取 node2 和 node3 或者 node1 和 node3 会得到 y；因为 node3 中 y 的时间戳是最新的 五、 Paxos 上图存在的问题： 在 x 设置 i 值的同时，这个过程还没做完，y 就准备插一手来设置 i 值了。 个人认为：核心问题发生在没有加锁 文章原话是说：“在 X 或 Y 写之前先做一次多数派读，以便确认是否有其他客户端进程已经在写了，如果有，则放弃” 解读 个人觉得这里的先做一次多数派读就是 Prepare 的过程 Paxos 也并不是发现有人在写就放弃的，而是在 Prepare 的时候就把自己的锁给加上了，然后抢占，所以才会导致活性的问题 这里如果单纯只是分布式加锁，也会存在一个问题，就是双方都只是加了锁，也都是简单的锁，因为请求可以同步过来，那么解决这个问题就是使用时间戳，只有最后一个锁，才是有效的 尚待完善… ","date":"2022-03-22","objectID":"/paxos/:2:2","tags":["分布式","paxos","共识"],"title":"Paxos","uri":"/paxos/"},{"categories":["专业基础"],"content":"网络基础学习整理","date":"2022-03-20","objectID":"/%E7%BD%91%E7%BB%9C/","tags":["网络","network","基础知识"],"title":"网络基础知识","uri":"/%E7%BD%91%E7%BB%9C/"},{"categories":["专业基础"],"content":"网络 ","date":"2022-03-20","objectID":"/%E7%BD%91%E7%BB%9C/:0:0","tags":["网络","network","基础知识"],"title":"网络基础知识","uri":"/%E7%BD%91%E7%BB%9C/"},{"categories":["专业基础"],"content":"一、CIDR CIDR（Classless Inter-Domain Routing，无类域间路由选择）它消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。它可以将好几个 IP 网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻 Internet 路由器的负担。 CIDR 记法 CIDR 还使用“斜线记法”，它又称为 CIDR 记法，即在 IP 地址后面加上一个斜线“/”，然后写上网络前缀所占的比特数（这个数值对应于三级编址中子网掩码中比特 1 的个数）。 IP 地址::={\u003c网络前缀*\u003e,\u003c*主机号\u003e} ","date":"2022-03-20","objectID":"/%E7%BD%91%E7%BB%9C/:1:0","tags":["网络","network","基础知识"],"title":"网络基础知识","uri":"/%E7%BD%91%E7%BB%9C/"},{"categories":["专业基础"],"content":"二、 IPSec （Internet Protocol Security） 学习链接 https://support.huawei.com/enterprise/zh/doc/EDOC1100008291/370abd69 https://support.huawei.com/enterprise/zh/doc/EDOC1100041456/f2298f86 https://cshihong.github.io/2019/04/09/IPSec-VPN%E4%B9%8BIKEv2%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/ ike2 2.1 概述 是一系列网络协议的集合 AH（Authentication Header） 验证头 报文头验证协议，提供数据校验功能。 ESP（Encapsulating Security Payload）封装安全载荷 提供数据加密功能 比较 AH 和 ESP 都能提供验证功能，主要采用算法 MD5、SHA1、SHA2-256**（建议）**、SHA2-384、SHA2-512 ESP 可以提供加密功能 DES、3DES、AES**（建议）** 2.2 IKE（Internet Key Exchange）因特网密钥交换 可以动态协商密钥 IKE 建立在 ISAKMP 框架之上，采用 DH（Diffie-Hellman）算法，可以提升密钥的安全性，并降低 IPSec 管理复杂度 2.3 IPSec 原理介绍 ipsec 在对等体之间建立安全联盟 SA（security association） SA 由三元组标识 SPI（security parameter index）安全参数索引： 32 位的唯一标识 SA 的数值 目的 IP 地址 使用的安全协议（AH 或 ESP） SA 是单向逻辑，为了建立双向连接，需要有两个安全联盟 另外，SA 的个数还与安全协议相关。如果只使用 AH 或 ESP 来保护两个对等体之间的流量，则对等体之间就有两个 SA，每个方向上一个。如果对等体同时使用了 AH 和 ESP，那么对等体之间就需要四个 SA，每个方向上两个，分别对应 AH 和 ESP。 封装模式 传输模式 隧道模式： IKE 与 IPSec 关系 对等体之间建立一个 IKE SA 完成身份验证和密钥信息交换后，在 IKE SA 的保护下，根据配置的 AH/ESP 安全协议等参数协商出一对 IPSec SA。此后，对等体间的数据将在 IPSec 隧道中加密传输 ","date":"2022-03-20","objectID":"/%E7%BD%91%E7%BB%9C/:1:1","tags":["网络","network","基础知识"],"title":"网络基础知识","uri":"/%E7%BD%91%E7%BB%9C/"},{"categories":["工具"],"content":"npm 包管理工具的使用学习","date":"2022-03-20","objectID":"/npm/","tags":["npm","包管理","实用工具"],"title":"Npm 使用","uri":"/npm/"},{"categories":["工具"],"content":"一、 npm install 参数 1.1 npm install 安装单个 packageName 包 无参数 默认情况 npm install packageName 默认情况下，不加参数。会安装包，并将依赖包的名称添加 package.json 中的 dependencies 字段。 –save 参数 npm install --save packageName 添加--save参数，与默认情况效果相同。会安装包，并将依赖包的名称添加到 package.json 中的 dependencies 字段。 –save-dev 参数 npm install --save-dev packageName 添加--save-dev参数，会安装包，并将依赖包的名称添加到 package.json 中的 devDependencies 字段。 安装某个包时，这个包中 package.json 的 dependencies 字段中的依赖会被自动安装，而 devDependencies 字段中的依赖不会被安装。 1.2 npm install 初始化项目 无参数 直接初始化 npm install 我们常用 npm install 初始化项目，安装项目所需的依赖。但更深入的细节是：直接使用 npm install 时，项目 package.json 中 dependencies 字段和 devDependencies 字段中的依赖包都会被安装。 –production 参数 npm install --production 添加--production安装项目所需的依赖时，只有 dependencies 字段中的依赖包会被安装，devDependencies 中的依赖包不会被安装。 –only=dev 参数 npm install --only=dev 添加--only=dev安装项目所需依赖时，只有 devDependencies 字段中的依赖包会被安装，dependencies 字段中的依赖包不会被安装。与添加–production 的效果刚好相反。 还有一个参数：–dev，它的效果与–only=dev 相同，但已经被废弃，请使用–only=dev 代替。 ","date":"2022-03-20","objectID":"/npm/:0:1","tags":["npm","包管理","实用工具"],"title":"Npm 使用","uri":"/npm/"},{"categories":["工具"],"content":"markdown写作学习","date":"2022-03-20","objectID":"/markdown/","tags":["markdown","写作","实用工具"],"title":"Markdown","uri":"/markdown/"},{"categories":["工具"],"content":"一、锚点-业内跳转 需要链接的地方 \u003cspan id = \"xxx\"\u003e 内容 \u003c/span\u003e 链接按钮 [链接标题](#xxx) ","date":"2022-03-20","objectID":"/markdown/:0:0","tags":["markdown","写作","实用工具"],"title":"Markdown","uri":"/markdown/"},{"categories":["工具"],"content":"文章描述","date":"2022-03-20","objectID":"/ssh/","tags":["运维","SSH","远程连接","实用工具"],"title":"SSH配置","uri":"/ssh/"},{"categories":["工具"],"content":"一、 远程用户：免密登陆+IP 重命名 用户目录下的.ssh目录内，添加配置文件config Host 47.103.81.142 HostName cloudHost User root ServerAliveInterval 20 C:\\Windows\\System32\\drivers\\etc\\hosts需要添加内容 47.103.81.142 cloudHost cat ~/.ssh/id_rsa.pub \u003e\u003e ~/.ssh/authorized_keys ","date":"2022-03-20","objectID":"/ssh/:0:1","tags":["运维","SSH","远程连接","实用工具"],"title":"SSH配置","uri":"/ssh/"},{"categories":["工具"],"content":"二、 连接不中断 修改配置文件~/.ssh/config 添加配置项ServerAliveInterval=30 ","date":"2022-03-20","objectID":"/ssh/:0:2","tags":["运维","SSH","远程连接","实用工具"],"title":"SSH配置","uri":"/ssh/"},{"categories":["理财"],"content":"投资理财的简要理解","date":"2022-03-20","objectID":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/","tags":["投资","理财"],"title":"投资概述","uri":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/"},{"categories":["理财"],"content":"🔗 https://www.zhihu.com/question/24435403/answer/276767603?utm_source=wechat_session\u0026utm_medium=social\u0026utm_oi=924545603512471552\u0026utm_content=group1_Answer\u0026utm_campaign=shareopn ","date":"2022-03-20","objectID":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/:0:0","tags":["投资","理财"],"title":"投资概述","uri":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/"},{"categories":["理财"],"content":"一、 钱的几种投资方式 1. 现金类资产 如：现金、银行存款、货币基金（这个和买的基金是一个东西？） 平均收益 3%-4%，几乎没有亏损。 一般银行整存整取一年，也就 1.7%左右，即整存10w，一年获利1750 按照 3%计算，10w 一年获利 3000 2. 固定收益类资产 如：国债、金融债、企业债、央行票据和债券型基金等 平均收益 5%-7%，亏损概率低，也不是不会亏损 按 5%计算，整存10w，一年获利5000 3. 权益类资产 如：股票、混合型基金、权证等 平均收益 10%-20%，但是遇到非常不好的行情，亏 50%也是有可能 ","date":"2022-03-20","objectID":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/:0:1","tags":["投资","理财"],"title":"投资概述","uri":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/"},{"categories":["理财"],"content":"二、理财要建立不同的“账户”，专款专用 （1） 明确需求 长期-低波动-低收益【打死不能动的钱】： 养老、买房（还款） 长期-中等波动-中等收益： 买车、生娃养娃、父母赡养、结婚 短期-高波动-高收益【小小投资，亏了不会哭的钱】：刨除长期需求后多出的钱 占比目前现金流的 5%，不要超过 10% （2） 建立“账户” 针对上述不同的需求，基于收入来源不同的分配比例划分到对应的需求，专款专用 按照月度/年度规划制定 excel 表格 这张表大概来说粉色部分就是预计算的资金缺口 如果粉丝部分不能填补，两种思路，增加风险投资、降低预期获利值 ","date":"2022-03-20","objectID":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/:0:2","tags":["投资","理财"],"title":"投资概述","uri":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/"},{"categories":["理财"],"content":"三、 指数基金（是不是常说的基金？） 指数基金是比较被推荐的 （1） 投资步骤 1）挑选处于低估值的指数 2）确定投资的金额 3）确定投资的频率 4）坚持不懈地定期不定额投入基金 5）高估值时卖出换仓其他低估值的基金 （2）如何估值 每股盈利/每股价格-10 年期国债收益率，值高则是低位，值低则是高位（多少是高点，多少是低点，如果评估，可能需要借鉴股票？） 市盈率： 一般市盈率 15 以下低估，15-20 持有，30 以上高估 钢铁，石化，纺织这种强周期的行业，市盈率不该太高 食品，消费，制药的抗周期性比较强，一般市盈率 20-30 倍是正常估值 还要结合历史低位分数线看，一般历史低位 10%分数线就是非常难得的定投机会了（什么是历史低位分数线？） 所以你可以参考**“且慢”或“天天”或“蛋卷”**这些基金平台提供的估值百分位，一般来讲，跌倒估值百分位 50%以下就可以进场了 ","date":"2022-03-20","objectID":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/:0:3","tags":["投资","理财"],"title":"投资概述","uri":"/%E7%90%86%E8%B4%A2%E6%A6%82%E8%BF%B0/"},{"categories":["native cloud"],"content":"Kubernetes 基础 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:0:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"一、架构 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:1:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"1.1 组件 Master ： scheduler、API-Server、rc（副本控制器） Etcd ： 存储（键值对）（分布式）（持久化） v2:内存 v3: DB Node ： kubelet（与容器运行时进行交互）、kube proxy（负载均衡，写入规则至 iptables） CoreDNS ： 为集群中 svc 创建“域名-IP”的对应解析 Ingress Controller ： 实现七层的代理 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:1:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"二、Pod 状态与生命周期管理 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:2:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"2.3 Init 容器 (1) 探针 init C 可以做服务探针，但是 init C 执行完之后就无法持续在线了 探针是由 kubelet 对容器执行的定期诊断，要执行的话，kubelet 需要调用容器实现的 handler execAction ：在容器中执行指定命令，成功则诊断成功 TCPSocketAction：对容器对应 IP 的 tcp 端口进行检查，如果端口打开，则诊断成功 HTTPGetAction：执行七层 HTTP 请求，状态码满足要求则诊断成功 两种探测方案 livenessProbe : 存活探测 livenessProbe-exec ：执行命令 readinessProbe ：就绪探测 readinessProbe-httpget ： http 请求 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:2:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"三、集群资源管理 资源清单类别 名称空间级别 工作负载型：Pod、RS、Deployment、Statefulset、DeamonSet、Job… 服务发现及负载均衡： Service、Ingress 集群级别（全局可见资源） namespace、node、role、clusterRole 元数据型资源 HPA ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.1 Node (1) 信息 (2) Lease 内容——节点心跳 Kubernetes 节点发送的心跳帮助你的集群确定每个节点的可用性，并在检测到故障时采取行动。 对于节点，有两种形式的心跳: 更新节点的 .status Lease 对象 在 kube-node-lease 命名空间中。 每个节点都有一个关联的 Lease 对象。 与 Node 的 .status 更新相比，Lease 是一种轻量级资源。 使用 Leases 心跳在大型集群中可以减少这些更新对性能的影响。 kubelet 负责创建和更新节点的 .status，以及更新它们对应的 Lease。 当状态发生变化时，或者在配置的时间间隔内没有更新事件时，kubelet 会更新 .status。 .status 更新的默认间隔为 5 分钟（比不可达节点的 40 秒默认超时时间长很多）。 kubelet 会每 10 秒（默认更新间隔时间）创建并更新其 Lease 对象。 Lease 更新独立于 NodeStatus 更新而发生。 如果 Lease 的更新操作失败，kubelet 会采用指数回退机制，从 200 毫秒开始 重试，最长重试间隔为 7 秒钟。 lease 资源全称 leases.coordination.k8s.io # 获取lease资源 kubectl get leases.coordination.k8s.io --all-namespaces (3) Condition conditions 字段描述所有 Running 节点的状态。 节点状况 描述 Ready 如节点是健康的并已经准备好接收 Pod 则为 True；False 表示节点不健康而且不能接收 Pod；Unknown 表示节点控制器在最近 node-monitor-grace-period 期间（默认 40 秒）没有收到节点的消息 DiskPressure True 表示节点存在磁盘空间压力，即磁盘可用量低, 否则为 False MemoryPressure True 表示节点存在内存压力，即节点内存可用量低，否则为 False PIDPressure True 表示节点存在进程压力，即节点上进程过多；否则为 False NetworkUnavailable True 表示节点网络配置不正确；否则为 False (4) PodCIDR PodCIDR 与 PodCIDRs 区别？ (5) ProviderID 当节点是公有云厂商提供的云主机时，这个属性表示公有云系统中对云主机的唯一标识，格式为：\u003cProviderName\u003e://\u003cProviderSpecificNodeID\u003e (6) Node 管理 一、node 调度之禁止调度（平滑维护）-cordon、drain、delete cordon、drain 和 delete 三个命令都会使 node 停止被调度，后期创建的 pod 不会继续被调度到该节点上，但操作的暴力程度却不一样。 1. cordon 停止调度（之后不可调度，临时从 K8S 集群隔离） 影响最小，只会将 node 标识为 SchedulingDisabled 不可调度状态。 之后 K8S 再创建的 pod 资源，不会被调度到该节点。 旧有的 pod 不会受到影响，仍正常对外提供服务。 禁止调度命令\"kubectl cordon node_name\"。 恢复调度命令\"kubectl uncordon node_name\"。（恢复到 K8S 集群中，变回可调度状态） 2. drain 驱逐节点（先不可调度，然后排干） 首先，驱逐 Node 上的 pod 资源到其他节点重新创建。 接着，将节点调为 SchedulingDisabled 不可调度状态。 禁止调度命令\"kubectl drain node_name –force –ignore-daemonsets –delete-local-data\" 恢复调度命令\"kubectl uncordon node_name\"。（恢复到 K8S 集群中，变回可调度状态） drain 方式是安全驱逐 pod，会等到 pod 容器应用程序优雅停止后再删除该 pod。 drain 驱逐流程：先在 Node 节点删除 pod，然后再在其他 Node 节点创建该 pod。所以为了确保 drain 驱逐 pod 过程中不中断服务（即做到\"无感知\"地平滑驱逐），必须保证要驱逐的 pod 副本数大于 1，并且采用了“反亲和策略”将这些 pod 调度到不同的 Node 节点上了！也就是说，在\"多个 pod 副本+反亲和策略\"的场景下，drain 驱逐过程对容器服务是没有影响的。 需要注意： 对节点执行维护操作之前（例如：内核升级，硬件维护等），您可以使用 kubectl drain 安全驱逐节点上面所有的 pod。 drain 安全驱逐方式将会允许 pod 里面的容器遵循指定的 PodDisruptionBudgets 执行优雅中止。也就是说，drain 安全驱逐可以做到：优雅地终止 pod 里的容器进程。 kubectl drain 返回成功表明所有的 pod （除了排除的那些）已经被安全驱逐（遵循期望优雅的中止期，并且没有违反任何应用程序级别的中断预算）。 然后，通过对物理机断电或者在云平台上删除节点所在的虚拟机，都能安全的将节点移除。 如下尚未学习 一般线上 K8S 的 PDB（PodDisruptionBudgets）配置的也是符合 Pod 驱逐的理想情况的，即 maxUnavailable 设置为 0，maxSurge 设置为 1： replicas:3strategy:rollingUpdate:maxSurge:1maxUnavailable:0type:RollingUpdate 默认情况下，kubectl drain 会忽略那些不能杀死的系统类型的 pod。drain 命令中需要添加三个参数：–force、–ignore-daemonsets、–delete-local-data –force 当一些 pod 不是经 ReplicationController, ReplicaSet, Job, DaemonSet 或者 StatefulSet 管理的时候就需要用–force 来强制执行 (例如:kube-proxy) –ignore-daemonsets 无视 DaemonSet 管理下的 Pod。即–ignore-daemonsets 往往需要指定的,这是因为 deamonset 会忽略 unschedulable 标签(使用 kubectl drain 时会自动给节点打上不可调度标签),因此 deamonset 控制器控制的 pod 被删除后可能马上又在此节点上启动起来,这样就会成为死循环.因此这里忽略 daemonset。 –delete-local-data 如果有 mount local volumn 的 pod，会强制杀掉该 pod。 为什么能优雅的驱逐？和先驱逐再新建的顺序有关还是和 PodDisruptionBudgets 策略有关 3. delete 删除节点 首先，驱逐 Node 节点上的 pod 资源到其他节点重新创建。 驱逐流程：先在 Node 节点删除 pod，然后再在其他 Node 节点上创建这些 pod。 node 节点删除，master 失去对其控制，该节点从 k8s 集群摘除。 delete 是一种暴力删除 node 的方式。在驱逐 pod 时是强制干掉容器进程，做不到优雅终止 Pod。相比较而言，显然 drain 更安全。 恢复调度（即重新加入到 K8S 集群中） delete 删除后，后续如果需重新加入 K8S 集群。则需要重启 node 节点的 kubelet 服务，重启后，基于 node 的自注册功能，该节点才能重新加入到 K8S 集群，并且恢复使用（即恢复可调度的身份）。 另外：如果 kubelet 服务重启后，node 节点系统时间跟其他节点不一致，则导致该节点证书会失效！kubelet 注册后，还需要手动 approve 签发 TLS 认证操作了。如下示例： 二、 node 添加（向 API server 添加） 1. 节点的 kubelet 向控制面自注册 当 kubelet 标志 --register-node 为 true（默认）时，它会尝试向 API 服务注册自己。 这是首选模式，被绝大多数发行版选用。 2. 手动添加 node 对象 { \"kind\": \"Node\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"10.240.79.157\", \"labels\": { \"name\": \"my-first-k8s-node\" } } } 说明： Kubernetes 会一直保存着非法节点对应的对象，并持续检查该节点是否已经 变得健康。 你，或者某个控制器必需显式地删除该 Node 对象以停止健康检查操作。 Node 对象的名称必须是合法的 DNS 子域名。 (7) 节点控制器 节点控制器是 Kubernetes 控制面组件，管理节点的方方面面。 节点控制器在节点的生命周期中扮演多个角色。 第一个是当节点注册时为它分配一个 CIDR 区段（如果启用了 CIDR 分配）。 第二个是保持节点控制器内的节点列表与云服务商所提供的可用机器列表同步。 如果在云环境下运行，只要某节点不健康，节点控制器就会询问云服务是否节点的虚拟机仍可用。 如果不可用，节点控制器会将该节","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.2 Namespaces 在一个 Kubernetes 集群中可以使用 namespace 创建多个 “虚拟集群”，实现集群间资源的隔离 (1) 一些细节点 删除一个 namespace 会自动删除所有属于该 namespace 的资源。 default 和 kube-system 命名空间不可删除；default、kube-system 以及 kube-public 都是默认命名空间 用户的普通应用在 defalut 下面 与集群管理相关的为整个集群提供服务的应用一般部署在 kube-system PersistentVolume 是不属于任何 namespace 的，但 PersistentVolumeClaim 是属于某个特定 namespace 的。 Event 是否属于 namespace 取决于产生 event 的对象。 v1.7 版本增加了 kube-public 命名空间，该命名空间用来存放公共的信息，一般以 ConfigMap 的形式存放。 namespaces 不包括 node 和 persistentVolume，那为啥 dashboard 可以实现 node 隔离呢？ ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:2","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.3 Label Label 是附着到 object 上（例如 Pod）的键值对。 \"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } k8s 将 lables 最终索引和反向索引用来优化查询和 watch，不要在 label 中使用大型、非标识的结构化数据，记录这样的数据应该用 annotation (1) 使用 label 情形 可以尝试如下标签 \"release\" : \"stable\", \"release\" : \"canary\" \"environment\" : \"dev\", \"environment\" : \"qa\", \"environment\" : \"production\" \"tier\" : \"frontend\", \"tier\" : \"backend\", \"tier\" : \"cache\" \"partition\" : \"customerA\", \"partition\" : \"customerB\" \"track\" : \"daily\", \"track\" : \"weekly\" \"team\" : \"teamA\",\"team:\" : \"teamB\" (2) 语法规则 Key 不能超过 63 个字符 可以使用前缀，前缀使用/分隔，前缀需要是 DNS 子域，不得超过 253 个字符，系统中自动化组件创建的 lable 必须指定前缀 起始必须是字母（大小写都可以）或数字，中间可以有连字符、下划线和点 Value 不得超过 63 个字符 起始必须是字母（大小写都可以）或数字，中间可以有连字符、下划线和点 (3) Selector 选择器 label 不是唯一的，多个对象可能有相同的 label 通过 selector 可以选择一个 obj 集合，对这个集合进行整体的操作 1. 方式一： equality-based 基于等值 可以使用操作符=、==、!= = 和 == 是一个意思 可使用逗号分隔多个表达式 2. 方式二：set-based 基于集合 可以使用 in、notion、!操作符 可以直接写出某个 label-key，表示直接选中，而不管对应的 value 是何值 ！表示没有该 label 的那些 obj environment in (production, qa) # env 等于product或者qa tier notin (frontend, backend) # tier 不等于frontend或者backend的资源 partition # 键为partition !partition # 键不为partition的全部 3. 资源中示例使用 selector pod apiVersion:v1kind:Podmetadata:name:cuda-testspec:containers:- name:cuda-testimage:\"k8s.gcr.io/cuda-vector-add:v0.1\"resources:limits:nvidia.com/gpu:1nodeSelector:accelerator:nvidia-tesla-p100 service 和 ReplicationController \"selector\": { \"component\": \"redis\", } selector:component:redis 等价于 component=redis 或者 component in（redis） job、Deployment、Replica Set 和 DemonSet 支持基于集合的需求 selector:matchLabels:component:redismatchExpressions:- {key: tier, operator: In, values:[cache] }- {key: environment, operator: NotIn, values:[dev] } matchLabels 是由 {key,value} 对组成的映射 有效的运算符包括 In、NotIn、Exists 和 DoesNotExist 来自 matchLabels 和 matchExpressions 的所有要求都按逻辑与的关系组合到一起,它们必须都满足才能匹配 4. 通过标签/selector 将 pod 分配给节点 场景：例如，确保 Pod 最终落在连接了 SSD 的机器上，或者将来自两个不同的服务 且有大量通信的 Pods 放置在同一个可用区。 一个简单的 nginx 配置文件 apiVerions:v1kind:Podmetadata:name:nginx-hxclabels:env:testspec:containers:- name:nginximage:nginximagePullPolicy:IfNotPresentnodeSelector:test/role:houWorker (4) 亲和性与反亲和性 相比于 selector 优点 语言更具表现力，（不局限于只能使用完全匹配且 AND 连接的规则） 可以设置“软需求”，即如果实在无法满足要求，仍然是可调度的 可以使用节点上的 pod 的标签来约束，而不仅仅是节点的标签 一、节点亲和性 requiredDuringSchedulingIgnoredDuringExecution “硬需求” 必须满足 preferredDuringScheduingIgnoredDuringExecution “软需求” 尽量满足 IgnoredDuringExecution 意味着，在 pod 运行时，如果标签不再满足要求也不会被驱逐 节点亲和性 affinity 部署示例 apiVersion:v1kind:Podmetadata:name:with-node-affinityspec:containers:- name:with-node-affinityimage:k8s.gcr.io/pause:2.0imagePullPolicy:IfNotPresentaffinity:nodeAffinity:requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:- matchExpressions:- key:test.com/roleoperator:Invalues:- hxcWorker- hxcWorker2preferredDuringSchedulingIgnoredDuringExecution:- weight:1preference:matchExpressions:- key:another/roleoperator:Invalues:- anotherWorker 亲和性支持的操作符 In、NotIn、Exists、DoesNotExist、Gt、Lt 反亲和性操作符 NotIn、DoesNotExist 如果同时指定nodeSelector和nodeAffinity，则两者都要满足，才能将 pod 调度到节点上 一个nodeSelectorTerms中的任意一个matchExpressions满足就可以调度 nodeAffinity:requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:# array- matchExpressions:- key:test.com/roleoperator:Invalues:- hxcWorker- hxcWorker2- key:matchoperator:Invalues:- yep- matchExpressions:- key:match2operator:Invalues:- hxcWorker- hxcWorker2# 两个matchExpressions满足一个即可 一个matchExpression内的全部规则都匹配才能调度 nodeAffinity:requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:# array- matchExpressions:- key:test.com/roleoperator:Invalues:- hxcWorker- hxcWorker2- key:matchoperator:Invalues:- yep# test.com/role和match两条标签均要满足才能调度 亲和性也是只在节点调度时有效，即如果运行时，标签修改，也不会驱逐节点 preferredDuringSchedulingIgnoredDuringExecution中的weight字段范围时 1-100，最终通过总分与其他节点 pk 二、Pod 间亲和性/反亲和性（约束 pod 标签而不是节点标签） pod 间亲和性需要大量的处理，会影响集群调度的速度，如果集群规模过大，不建议使用 # 示例apiVersion:v1kind:Podmetadata:name:with-pod-affinityspec:affinity:podAffinity:# 关键结构一：podAffinityrequiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- S1topologyKe","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:3","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.4 Annotation Annotation-注解。可以为 K8S 资源对象添加任意的非标识性元数据。 这些元数据可以理解为记录了一些备注信息，与 label 不同点在于，label 主要用于标识且选择对象。 常用记录信息 由声明性配置所管理的字段。 将这些字段附加为注解，能够将它们与客户端或服务端设置的默认值、 自动生成的字段以及通过自动调整大小或自动伸缩系统设置的字段区分开来。 构建、发布或镜像信息（如时间戳、发布 ID、Git 分支、PR 数量、镜像哈希、仓库地址）。 指向日志记录、监控、分析或审计仓库的指针。 可用于调试目的的客户端库或工具信息：例如，名称、版本和构建信息。 用户或者工具/系统的来源信息，例如来自其他生态系统组件的相关对象的 URL。 轻量级上线工具的元数据信息：例如，配置或检查点。 负责人员的电话或呼机号码，或指定在何处可以找到该信息的目录条目，如团队网站。 从用户到最终运行的指令，以修改行为或使用非标准功能。 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:4","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.5 Taint and Toleration 具有taint的 node 和 pod 是互斥关系；具有节点亲和性关系的 node 和 pod 是相吸关系 每个节点可以应用一个或多个taint 如果设置了 taint，那些不能容忍该 taint 的 pod，不会被该节点接受；如果将 toleration 应用在 pod 上，则表示这些 pod 可以被调度到具有相应 taint 的节点上 (1) Node 设置 taint 见命令章节 (2) Pod 设置 toleration # spec 中 设置toleration字段toleration:- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoSchedule\"- key:\"node.alpha.kubernetes.io/unreachable\"operator:\"Exists\"effect:\"NoExecute\"tolerationSeconds:6000 operator taint 和 toleration 相匹配是指具有一样的 key 和 effect 如果operator是Exists，则key和effect相同即可 如果operator是Equal，则key,effect和value都需要一样 特殊情况 如果key为空，且operator为Exists，表示该 toleration 能容忍任意的 taint 如果effect为空，则该 toleration 可以与任意的键名相同的effect相匹配 效果 NoSchedule: 不会将 Pod 分配到该节点 PreferNoSchedule：尝试尽量不将 Pod 分配到该节点 NoExecute: 不会将 Pod 分配到该节点，或者将 Pod 从该节点驱逐 此时，tolerationSeconds表明了该 Pod 还能继续在节点上运行的时间 (3) 应用场景 专用节点 将某些节点专门分配给特定的一组用户使用 kubectl taint nodes nodename dedicated=groupName:NoSchedule 该方案只能使得不是该 group 的 pod 不被分配到这些专用节点上运行，如果想让该 group 的 pod 只在这些专用节点上运行，可以配合 lable 一起使用 配置特殊硬件的节点 比如 GPU 资源 kubecl taint nodes nodename special=true:NoSchedule 基于污点的驱逐 每个 Pod 中配置的当节点出现问题时的驱逐行为 上述的专用节点和配置特殊硬件的节点等应用场景中可以用到准入控制器 (4) 基于污点的驱逐 某种条件为真时，节点控制器会自动给节点添加污点，这些内置的污点包括 node.kubernetes.io/not-ready : 节点未准备好，相当于节点的Ready状态时False node.kubernetes.io/unreachable: 节点控制器访问不到节点，相当于节点的Ready状态为Unkonwn node.kubernetes.io/memory-pressure: 节点存在内存压力 node.kubernetes.io/disk-pressure: 节点存在磁盘压力 node.kubernetes.io/pid-pressure: 节点存在 PID 压力 node.kubernetes.io/network-unavilable: 节点网络不可用 node.kubernetes.io/unschedulable: 节点不可调度 node.cloudprovider.kubernetes.io/uninitialized: 外部云平台驱动，给节点添加了一个污点标志为不可用 K8S 会自动给 Pod 添加一个 key 为node.kubernetes.io/not-ready的容忍度，并配置toleration=300,除非用户的 Pod 配置中已经设置了该项 同样，K8S 也会设置unreachable中toleration=300,即相关问题被检测出后，Pod 能够继续在当前节点运行 5 分钟 (5) 基于节点状态添加污点 控制平面使用节点控制器自动创建于节点状况对应的带有NoSchedule的污点 调度器在进行调度时检查污点，而不是检查节点状况。 DemonSet 控制器为 Pod 添加的容忍度包括memory-pressure,disk-pressure,pid-pressure,unschedulable,network-navailable ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:5","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"3.6 垃圾收集 (1) 垃圾收集的资源类型 失败的 Pod 已完成的 Job 不再存在属主引用的对象 未使用的容器和容器镜像 动态制备的、StorageClass 回收策略为 Delete 的 PV 卷 阻滞或者过期的 CertificateSigningRequest (CSRs) 在以下情形中删除了的 节点 对象： 当集群使用云控制器管理器运行于云端时； 当集群使用类似于云控制器管理器的插件运行在本地环境中时。 节点租约对象 (2) Owner 和 Dependent（收供养者，依赖者） 具有 Owner 的对象被称为是 Owner 的 Dependent，例如一个 ReplicaSet 是一组 Pod 的 Owner 每个 Dependent 对象具有一个指向其所属对象的metadata.ownerReferences字段 通过kubectl get pods coredns-558bd4d5db-45f7v -n kube-system --output=yaml查看 metadata 中的ownerReference信息 apiVersion:v1kind:Podmetadata:creationTimestamp:'2022-03-14T07:51:26Z'generateName:coredns-558bd4d5db-labels:k8s-app:kube-dnspod-template-hash:558bd4d5dbname:coredns-558bd4d5db-45f7vnamespace:kube-systemownerReferences:- apiVersion:apps/v1blockOwnerDeletion:truecontroller:truekind:ReplicaSetname:coredns-558bd4d5dbuid:2dc8bfca-ac8f-4e24-a64b-f5c79860e862resourceVersion:'724'uid:db321d22-df72-40da-a667-64b2183ecac5 (3) 控制垃圾收集器删除 Dependent 当删除对象时，可以指定是否该对象的 Dependent 也自动删除掉。自动删除 Dependent 也称为级联删除。 K8S 有两种级联删除模式：background 模式和foreground 模式 如果删除对象时，不自动删除它的 Dependent，这些 Dependent 被称作是原对象的孤儿(Orphaned) 1. Background 级联删除 默认情况下，K8S 使用background的级联删除方案，除非手动设置了使用foreground或者选择遗弃 dependent 对象 K8S 会立即删除 Owner 对象，然后垃圾收集器会在后台删除这些 Dependent 2. Foreground 级联删除 被删除的 Owner 首先进入deletion in progress状态，Ower 对象将会 K8S 将 Owner 的metadata.deletionTimestamp字段设置为对象被标记为要删除的时间点 K8S 将 Owner 的metadata.finalizers字段设置为foregroundDeletion 在deletion in progress删除过程完成之前，K8S API 还是可以看到该对象的 当 Owner 进入deletion in progress状态之后，控制器开始删除 Owner 的 Dependent，删除完依赖对象之后，删除 Owner 对象，这时，就无法通过 K8S API 查看到该对象 Dependent 对象如果带有ownerReference.blockOwnerDeletion=true字段，则可能会阻塞 Owner 对象被删除。[https://kubernetes.io/zh/docs/tasks/administer-cluster/use-cascading-deletion/#use-foreground-cascading-deletion] (4) 对未使用容器和镜像的垃圾收集 kubelet会每五分钟对未使用的镜像执行一次垃圾收集；每一分钟对未使用的容器执行一次垃圾收集 如果想要自定义对容器和镜像的垃圾收集选项，可以配置一个配置文件,基于KubeletConfiguration资源类型来调整与垃圾收集相关的 kubelet 行为；由于 kubelet 对容器和镜像会有垃圾回收相关的管理，所以不推荐使用外部的第三方垃圾收集工具。 容器镜像生命周期 K8S 通过镜像管理器（Image Manager）来管理所有镜像的生命周期，Image Manager 是 Kubelet 的一部分，工作时需要与cadvisor协作 kubelet 垃圾收集时的考虑因素包括HighThresholdPercent,LowThresholdPercent 如果磁盘用量超出配置等High时会触发垃圾收集，垃圾收集器会基于镜像上次使用的时间来按顺序删除镜像，kubelet 会持续删除镜像，直到磁盘用量达到low 容器垃圾收集 kubelet 会基于如下变量对容器执行垃圾收集，这些变量可以手动定义 MinAge: 当容器年龄大于该值时 kubelet 才可以垃圾回收该容器 MaxPerPodContainer ： 每个 Pod 可以包含的已死亡的容器数量上限 MaxContainers ： 集群中可以存在的已死亡的容器数量上限 MaxPerPodContainer和MaxContainers可能冲突，冲突时通过调整MaxPerPodContainer来解决 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:3:6","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"四、控制器 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.1 Deployment deployment 会去创建对应的 rs，rs 再去创建对应的 pod dp 支持滚动升级和回滚应用（通过控制 rs 的版本） 比如滚动更新会创建新的 rs，但是旧的 rs 不删除，这样就可以实现回滚 dp 支持暂停和继续（通过控制 rs 存在的数量？？？） ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.2 StateFulSet 有状态服务不太好处理，docker 是通过持久化存储卷的方式来实现，k8s 提供了 statefule 来支持 但是对于 mysql，可能现在的支持还不是特别的完善 通过稳定的持久化存储，pod 重新调度后能够访问到相同的持久化数据，基于 PVC 来实现 稳定的网络标识：PodName 和 HostName 不变，基于 headless service(即没有 cluster ip 的 service)来实现 有序部署，pod 的部署是有前后顺序的，基于 init C 来实现 有序收缩，有序删除 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:2","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.3 DaemonSet(还不是特别理解) DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。 使用 DaemonSet 的一些典型用法： 运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。 在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。 一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。 一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU 要求。 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:3","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.4 ReplicationController （已经是过去时了）， ReplicaSet RC 就是最基本，维持 pod 副本数不多也不少 RS 与 RC 没有什么不同，支持集合式的 selector RS 具有扩容、缩容功能 kubectl explain rs ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:4","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.5 Job、 CronJob 处理脚本执行的问题 job 如果运行脚本没有 0 成功退出，会再次重新运行 cronjon 只是在 job 的基础上实现周期性运行（通过在特定的时间循环创建 job 来实现） ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:5","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"4.6 Horizontal Pod Autoscaling （水平自动扩展） 可以理解为不是一个控制器，而是一个控制器的附属品 创建了一个 dp 之后，可以再创建一个 hpa 来管理控制 dp 可以通过一些资源指标（CPU，mem）等来实现 pod 缩放 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:4:6","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"五、服务发现与路由 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:5:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"5.1 service 每个 svc 可以理解为一个微服务 (1) svc 负载均衡 只能实现 4 层负载均衡，没有 7 层负载均衡能力 (2) svc 类型 clusterIP ： 自动分配一个 cluster 内部（节点内部）可以访问的 IP，即节点内其他 pod 可以通过这个 ip 访问到 svc 即访问到 svc 对应的 pod NodePort ： 在 clusterIp 的基础上，分配了一个端口，可以通过 IP：port 方式来访问服务，这种方式就将服务暴露到外部去了，一般端口是会做一个映射的 80-\u003e30001 这种 LoadBalancer ：在 nodeport 的基础上，借助 cloud provider 创建一个外部负载均衡器，将请求转发到 nodeIP：nodeport，相当于 svc 可能会在好几个 node 节点上都创建多个 pod，那么可以在这些 node 之前加一个负载均衡器来实现对于 nodeIP：port 这种方式的 svc 的访问，均衡器可以是自己整的 nginx，这里则是指云服务提供商提供的服务 ExternalName ： 只是为了在集群内部定义一个统一的对外面的某个访问的 svc，因为可能集群内部多个 pod 都会要访问这个外部服务，但是如果外部 IP 变了的话，就要改动很大，而使用 ExternalName 这种 svc 的话，则只用改这个 svc 中的配置 (3) svc 原理 client 访问 svc，转发到对应的 pod 是通过 iptables 来实现的 iptables 规则的生成是通过 kube-proxy（服务发现）来实现的 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:5:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"六、 身份与权限控制 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:6:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"6.1 kubeconfig kubeconfig 是 kubernetes 集群中各个组件(api-server 客户端)连入 api-server 的时候 , 使用的认证格式的客户端配置文件 查看 kubeconfig 配置文件 kubectl config view kubeconfig 证书 和 token 两种认证方式是 K8S 中最简单通用的两种认证方式 生成 kubeconfig 的配置步骤 1、定义变量 export KUBE_APISERVER=“https://172.20.0.2:6443” 2、设置集群参数 kubectl config set-cluster kubernetes –certificate-authority=/etc/kubernetes/ssl/ca.pem –embed-certs=true –server=${KUBE_APISERVER} #可以指定路径 kubeconfig=/root/config.conf 说明：集群参数主要设置了所需要访问的集群的信息。使用 set-cluster 设置了需要访问的集群，如上为 kubernetes；–certificate-authority 设置了该集群的公钥；–embed-certs 为 true 表示将 –certificate-authority 证书写入到 kubeconfig 中；–server 则表示该集群的 kube-apiserver 地址。 3、设置客户端认证参数 kubectl config set-credentials admin –client-certificate=/etc/kubernetes/ssl/admin.pem –embed-certs=true –client-key=/etc/kubernetes/ssl/admin-key.pem #可以指定路径 kubeconfig=/root/config.conf 说明：用户参数主要设置用户的相关信息，主要是用户证书。如上的用户名为 admin，证书为：/etc/kubernetes/ssl/admin.pem，私钥为：/etc/kubernetes/ssl/admin-key.pem。注意客户端的证书首先要经过集群 CA 的签署，否则不会被集群认可。此处使用的是 ca 认证方式，也可以使用 token 认证，如 kubelet 的 TLS Boostrap 机制下的 bootstrapping 使用的就是 token 认证方式。 4、设置上下文参数 kubectl config set-context kubernetes –cluster=kubernetes –user=admin #可以指定路径 kubeconfig=/root/config.conf 说明：上下文参数将 集群参数和用户参数关联起来。如上面的上下文名称为 kubenetes，集群为 kubenetes，用户为 admin，表示使用 admin 的用户凭证来访问 kubenetes 集群的 default 命名空间，也可以增加 –namspace 来指定访问的命名空间。 5、设置默认上下文 kubectl config use-context kubernetes #可以指定路径 kubeconfig=/root/config.conf 说明：最后使用kubectl config use-context kubernetes 来使用名为 kubenetes 的环境项来作为配置。如果配置了多个环境项，可通过切换不同的环境项名字来访问到不同的集群环境。 完整的 k8s 的认证方式 https://zhuanlan.zhihu.com/p/97797321 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:6:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"七、 网络 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:7:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"八、 存储 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:8:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"8.2 ConfigMap (1) 是什么？ configMap 就是 k8s 中的配置，本质是键值对 (2) 为什么用 configMap ? 不是 yml 吗？有哪些地方需要用到配置？ (3) 方向（configMap 主要考虑创建和使用两部分） 创建 使用 配置文件（configMap、secret 都存储在 etcd 中了） configMap 可以用来保存单个属性，也可以保存配置文件 (4) configMap 作用 设置环境变量的值 设置命令行参数 在数据卷中创建 config 文件 (5) 与 secret 的区别： configMap 是不需要加密的配置，其他基本相同 (6) 其他资料 配置中心的概念，比如携程的开源分布式配置中心 Apollo ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:8:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"九、 集群扩展 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:9:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"十、配置 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:10:0","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"9.1 apiVersion Deployment 可用 apps/v1 1.6版本之前 apiVsersion：extensions/v1beta1 1.6版本到1.9版本之间：apps/v1beta1 1.9版本之后:apps/v1 pods 可以直接是 v1 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:10:1","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":["native cloud"],"content":"9.2 spec 对于 Deployment，spec 下的 selector 字段是 required 的 meta 理解为类型属性的描述 metav1.TypeMeta -\u003e kind/apiVersion spce：定义 API 对象类型私有属性。 -\u003e spec. (也是这个字段使得不同 API 对象得以区分) Status : 描述对象的状态 ","date":"2022-03-19","objectID":"/kubernetes%E5%9F%BA%E7%A1%80/:10:2","tags":[],"title":"Kubernetes基础","uri":"/kubernetes%E5%9F%BA%E7%A1%80/"},{"categories":null,"content":" 警告 Sorry, this article has not been completely translated into French. Welcome to take the time to propose a translation by  making a PR to the theme!  LoveIt is a clean, elegant but advanced blog theme for Hugo developed by Dillon. It is based on the original LeaveIt Theme and KeepIt Theme. Hugo Theme LoveItHugo Theme LoveIt \" Hugo Theme LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"À propos de LoveIt","uri":"/about/"},{"categories":null,"content":"Features Performance and SEO  Optimized for performance: 99/100 on mobile and 100/100 on desktop in Google PageSpeed Insights  Optimized SEO performance with a correct SEO SCHEMA based on JSON-LD  Google Analytics supported  Fathom Analytics supported  Search engine verification supported (Google, Bind, Yandex and Baidu)  CDN for third-party libraries supported  Automatically converted images with Lazy Load by lazysizes Appearance and Layout / Responsive layout / Light/Dark mode  Globally consistent design language  Pagination supported  Easy-to-use and self-expanding table of contents  Multilanguage supported and i18n ready  Beautiful CSS animation Social and Comment Systems  Gravatar supported by Gravatar  Local Avatar supported  Up to 64 social links supported  Up to 28 share sites supported  Disqus comment system supported by Disqus  Gitalk comment system supported by Gitalk  Valine comment system supported by Valine  Facebook comments system supported by Facebook  Telegram comments system supported by Comments  Commento comment system supported by Commento  Utterances comment system supported by Utterances Extended Features  Search supported by Lunr.js or algolia  Twemoji supported  Automatically highlighting code  Copy code to clipboard with one click  Images gallery supported by lightgallery.js  Extended Markdown syntax for Font Awesome icons  Extended Markdown syntax for ruby annotation  Extended Markdown syntax for fraction  Mathematical formula supported by $ \\KaTeX $  Diagrams shortcode supported by mermaid  Interactive data visualization shortcode supported by ECharts  Mapbox shortcode supported by Mapbox GL JS  Music player shortcode supported by APlayer and MetingJS  Bilibili player shortcode  Kinds of admonitions shortcode  Custom style shortcode  Custom script shortcode  Animated typing supported by TypeIt  Dynamic scroll supported by Smooth Scroll  Cookie consent banner supported by cookieconsent … ","date":"2019-08-02","objectID":"/about/:0:1","tags":null,"title":"À propos de LoveIt","uri":"/about/"},{"categories":null,"content":"License LoveIt is licensed under the MIT license. Check the LICENSE file for details. Thanks to the authors of following resources included in the theme: normalize.css Font Awesome Simple Icons Animate.css Smooth Scroll autocomplete.js Lunr.js algoliasearch lazysizes object-fit-images Twemoji lightgallery.js clipboard.js Sharer.js TypeIt $ \\KaTeX $ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:0:2","tags":null,"title":"À propos de LoveIt","uri":"/about/"}]